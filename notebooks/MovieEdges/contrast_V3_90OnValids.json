{
    "contrast": {
        "FBL": {
            "z": [
                0,
                127.00389099121094
            ],
            "y": [
                0,
                121.05058288574219
            ]
        },
        "NPM1": {
            "z": [
                0,
                134.0806427001953
            ],
            "y": [
                0,
                133.25807189941406
            ]
        },
        "SON": {
            "z": [
                0,
                41.059322357177734
            ],
            "y": [
                0,
                30.25423812866211
            ]
        },
        "SMC1A": {
            "z": [
                0,
                16.45161247253418
            ],
            "y": [
                0,
                16.45161247253418
            ]
        },
        "HIST1H2BJ": {
            "z": [
                0,
                62.704917907714844
            ],
            "y": [
                0,
                45.98360824584961
            ]
        },
        "LMNB1": {
            "z": [
                0,
                80.05813598632812
            ],
            "y": [
                0,
                166.0465087890625
            ]
        },
        "NUP153": {
            "z": [
                0,
                60.929203033447266
            ],
            "y": [
                0,
                31.592920303344727
            ]
        },
        "SEC61B": {
            "z": [
                0,
                116.61585235595703
            ],
            "y": [
                0,
                60.64024353027344
            ]
        },
        "ATP2A2": {
            "z": [
                0,
                104.31818389892578
            ],
            "y": [
                0,
                52.15909194946289
            ]
        },
        "SLC25A17": {
            "z": [
                0,
                12.439023971557617
            ],
            "y": [
                0,
                12.439023971557617
            ]
        },
        "RAB5A": {
            "z": [
                0,
                5.3125
            ],
            "y": [
                0,
                5.3125
            ]
        },
        "TOMM20": {
            "z": [
                0,
                45.882354736328125
            ],
            "y": [
                0,
                48.52941131591797
            ]
        },
        "LAMP1": {
            "z": [
                0,
                18.56012725830078
            ],
            "y": [
                0,
                32.278480529785156
            ]
        },
        "ST6GAL1": {
            "z": [
                0,
                8.018867492675781
            ],
            "y": [
                0,
                27.264150619506836
            ]
        },
        "TUBA1B": {
            "z": [
                0,
                50.06544494628906
            ],
            "y": [
                0,
                61.413612365722656
            ]
        },
        "CETN2": {
            "z": [
                0,
                0.930656909942627
            ],
            "y": [
                0,
                1.861313819885254
            ]
        },
        "GJA1": {
            "z": [
                0,
                5.483870983123779
            ],
            "y": [
                0,
                5.483870983123779
            ]
        },
        "TJP1": {
            "z": [
                0,
                1.314432978630066
            ],
            "y": [
                0,
                10.515463829040527
            ]
        },
        "DSP": {
            "z": [
                0,
                2.0564515590667725
            ],
            "y": [
                0,
                2.0564515590667725
            ]
        },
        "CTNNB1": {
            "z": [
                0,
                40.89622497558594
            ],
            "y": [
                0,
                18.04245376586914
            ]
        },
        "AAVS1": {
            "z": [
                0,
                74.14893341064453
            ],
            "y": [
                0,
                144.68084716796875
            ]
        },
        "ACTB": {
            "z": [
                0,
                16.276596069335938
            ],
            "y": [
                0,
                21.70212745666504
            ]
        },
        "ACTN1": {
            "z": [
                0,
                7.285714149475098
            ],
            "y": [
                0,
                19.125
            ]
        },
        "MYH10": {
            "z": [
                0,
                1.9318181276321411
            ],
            "y": [
                0,
                22.215909957885742
            ]
        },
        "PXN": {
            "z": [
                0,
                1.7708333730697632
            ],
            "y": [
                0,
                3.5416667461395264
            ]
        }
    },
    "version": {
        "../tools/common.py": "import sys\nimport yaml\nimport uuid\nimport datetime\nimport concurrent\nimport numpy as np\nimport pandas as pd\nimport multiprocessing\nfrom pathlib import Path\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\nfrom aicscytoparam import cytoparam\nfrom sklearn.decomposition import PCA\nfrom scipy import cluster as spcluster\nfrom skimage import measure as skmeasure\nfrom multiprocessing import shared_memory as smem\nfrom sklearn import discriminant_analysis as sklda\nfrom cvapipe_analysis.tools import io, general, controller, shapespace\n\ndef get_map_point_shape(control, device, row, inner_mesh=None, outer_mesh=None):\n    device.row = row\n    nisos = control.get_number_of_interpolating_points()\n    if inner_mesh is None:\n        inner_alias = control.get_inner_most_alias_to_parameterize()\n        inner_mesh = device.read_map_point_mesh(inner_alias)\n    if outer_mesh is None:\n        outer_alias = control.get_outer_most_alias_to_parameterize()\n        outer_mesh = device.read_map_point_mesh(outer_alias)\n    domain, origin = cytoparam.voxelize_meshes([outer_mesh, inner_mesh])\n    coords_param, _ = cytoparam.parameterize_image_coordinates(\n        seg_mem=(domain>0).astype(np.uint8),\n        seg_nuc=(domain>1).astype(np.uint8),\n        lmax=control.get_lmax(), nisos=[nisos, nisos]\n    )\n    domain_nuc = (255*(domain>1)).astype(np.uint8)\n    domain_mem = (255*(domain>0)).astype(np.uint8)\n    return domain, domain_nuc, domain_mem, coords_param\n\ndef get_stack_with_single_cell_from_two_populations(data, scale, bbox, special_raw_contrast={}, text_label=\"lda\"):\n    ncells = 15\n    # Loading main control for correct gene order and gene contrast settings\n    path_config = Path(\"/allen/aics/assay-dev/MicroscopyOtherData/Viana/projects/cvapipe_analysis/\")\n    config = general.load_config_file(path_config)\n    control = controller.Controller(config)\n    # Get figure parameters\n    (yyi, yyf, yzi, yzf), bbox, figargs = contact_sheet_params(box_size=bbox, ylow=110, zlow=70)\n    views = []\n    for ncell, celldata in enumerate(data):\n        fig, axs = plt.subplots(1, 3, figsize=(1*scale, 3*scale), **figargs, dpi=150)\n        for ch, ax in enumerate(axs):\n            ax.axis(\"off\")\n            too_big = False\n            ch_used = ch+2 if ch < 2 else 3\n            proj = Projector(celldata[\"img\"][[0,1,ch_used]], mask_on=True, force_fit=True, box_size=bbox)\n            if ch==0: #raw data\n                cmap = \"gray\"\n                mode = {\"nuc\":\"max\",\"mem\":\"max\",\"gfp\":\"max\"}\n                vmin, vmax = control.get_optimal_raw_contrast(celldata['gene'])\n                if celldata['gene'] in special_raw_contrast:\n                    vmin, vmax = special_raw_contrast[celldata['gene']]\n                proj.set_vmin_vmax_gfp_values(vmin, vmax)\n            if ch==1: #seg data\n                cmap = \"binary\"\n                mode = {\"nuc\":\"max\",\"mem\":\"max\",\"gfp\":\"mean\"}\n                vmin, vmax = control.get_optimal_seg_contrast(celldata['gene'])\n                proj.set_vmin_vmax_gfp_values(vmin, vmax)\n            if ch==2: #seg data\n                cmap = \"binary\"\n                mode = {\"nuc\":\"center_nuc\",\"mem\":\"center_nuc\",\"gfp\":\"center_nuc\"}\n                proj.set_gfp_percentiles((20, 100), local=True)\n            try:\n                proj.set_projection_mode(ax=\"z\", mode=mode)\n                proj.compute()\n                contourz = proj.get_proj_contours()\n                pz = proj.projs[\"gfp\"].copy()\n                proj.set_projection_mode(ax=\"y\", mode=mode)\n                proj.compute()\n                contoury = proj.get_proj_contours()\n                py = proj.projs[\"gfp\"].copy()\n                im = np.concatenate([py[yyi:yyf, :], pz[yzi:yzf, :]], axis=0)\n                ax.imshow(im, cmap=cmap, origin=\"lower\", vmin=proj.gfp_vmin, vmax=proj.gfp_vmax)\n                for alias_cont, alias_color in zip([\"nuc\", \"mem\"], [\"cyan\", \"magenta\"]):\n                    [ax.plot(c[:,1], c[:,0]-yyi, lw=0.5, color=alias_color) for c in contoury[alias_cont]]\n                    [ax.plot(c[:,1], c[:,0]+(yyf-yyi)-yzi, lw=0.5, color=alias_color) for c in contourz[alias_cont]]\n            except:\n                too_big = True\n                print(\"Cell is too big\")\n                pass\n            ax.set_ylim(1, im.shape[0])\n            ax.set_xlim(1, im.shape[1])\n        axs[0].set_title(f\"{celldata['gene']}-{celldata['dataset']} - {(ncell+1)%(ncells+1):02d}\", fontsize=10)\n        axs[1].set_title(f\"{text_label}={celldata[text_label]}\", fontsize=10)\n        axs[2].set_title(f\"ID={celldata['CellId']}\", fontsize=10)\n        plt.tight_layout()\n        fig.canvas.draw()\n        plt.show(close=True)\n        if not too_big:\n            views.append(np.array(fig.canvas.renderer._renderer))\n    return resize_and_group_images(views)\n\ndef normalize_image_to_01_interval(img, vmin, vmax):\n    if vmax < 1e-3:\n        return img\n    img = np.clip(img, vmin, vmax)\n    img = (img-vmin)/(vmax-vmin)\n    return img\n\ndef make_contact_sheet_avgseg_channel(data, bbox, file_prefix=None, contrast=None, ylow=110, zlow=70, nucleus_contour_off=[]):\n    # Loading main control for correct gene order and gene contrast settings\n    path_config = Path(\"/allen/aics/assay-dev/MicroscopyOtherData/Viana/projects/cvapipe_analysis/\")\n    config = general.load_config_file(path_config)\n    control = controller.Controller(config)\n    genes = control.get_gene_names()\n    (yyi, yyf, yzi, yzf), bbox, figargs = contact_sheet_params(box_size=bbox, ylow=ylow, zlow=zlow)\n    fig, axs = plt.subplots(len(genes), 1, figsize=(1,len(genes)), **figargs)\n    for gene, ax in zip(genes, axs):\n        if gene not in data:\n            continue\n        ax.axis(\"off\")\n        instance = data[gene][0][\"img\"][[0, 1, 2]]\n        mode = {\"nuc\":\"center_nuc\",\"mem\":\"center_nuc\",\"gfp\":\"center_nuc\"}\n        proj = Projector(instance, mask_on=True, box_size=bbox, force_fit=True)\n        #\n        # Z projection\n        #\n        if contrast is not None:\n            vmin, vmaxz = contrast[gene][\"z\"]\n        else:\n            vmin, vmax = control.get_optimal_avgseg_contrast(gene)\n        proj.set_projection_mode(ax=\"z\", mode=mode)\n        proj.compute()\n        pz = proj.projs[\"gfp\"].copy()\n#         pz = normalize_image_to_01_interval(pz, vmin, vmax)\n        contourz = proj.get_proj_contours()\n        #\n        # Y projection\n        #\n        if contrast is not None:\n            vmin, vmaxy = contrast[gene][\"y\"]\n        else:\n            vmin, vmax = control.get_optimal_avgseg_contrast(gene)\n        vmax = np.max([vmaxz, vmaxy])\n        proj.set_projection_mode(ax=\"y\", mode=mode)\n        proj.compute()\n        py = proj.projs[\"gfp\"].copy()\n#         py = normalize_image_to_01_interval(py, vmin, vmax)\n        contoury = proj.get_proj_contours()\n        #\n        # Combine projections\n        #\n        im = np.concatenate([py[yyi:yyf, :], pz[yzi:yzf, :]], axis=0)\n        im = normalize_image_to_01_interval(im, 0, vmax)\n        ax.imshow(im, cmap=\"inferno\", origin=\"lower\", vmin=0, vmax=1)\n        for alias_cont, alias_color in zip([\"nuc\", \"mem\"], [\"cyan\", \"magenta\"]):\n            if gene in nucleus_contour_off and alias_cont==\"nuc\":\n                continue\n            [ax.plot(c[:,1], c[:,0]-yyi, lw=0.5, color=alias_color) for c in contoury[alias_cont]]\n            [ax.plot(c[:,1], c[:,0]+(yyf-yyi)-yzi, lw=0.5, color=alias_color) for c in contourz[alias_cont]]\n        ax.set_xlim(0, im.shape[1])\n        ax.set_ylim(0, im.shape[0])\n    if file_prefix is not None:\n        plt.savefig(f\"{file_prefix}\", dpi=300)\n    plt.show()\n\ndef make_contact_sheet_raw_and_seg_channels(data, bbox, file_prefix, special_raw_contrast={}):\n    # Loading main control for correct gene order and gene contrast settings\n    path_config = Path(\"/allen/aics/assay-dev/MicroscopyOtherData/Viana/projects/cvapipe_analysis/\")\n    config = general.load_config_file(path_config)\n    control = controller.Controller(config)\n    genes = control.get_gene_names()\n    ncells = len(data[genes[0]])\n    # Get figure parameters\n    (yyi, yyf, yzi, yzf), bbox, figargs = contact_sheet_params(box_size=bbox, ylow=110, zlow=70)\n    # Loop over genes and raw and seg channels\n    for ncell in range(ncells):\n        for ch, chname in enumerate([\"raw\", \"seg\"]):\n            fig, axs = plt.subplots(len(genes), 1, figsize=(1,len(genes)), **figargs)\n            for gene, ax in zip(genes, axs):\n                ax.axis(\"off\")\n                instance = data[gene][ncell][\"img\"][[0, 1, 2+ch]]\n                proj = Projector(instance, mask_on=True, box_size=bbox, force_fit=True)\n                if ch: #seg data\n                    mode = {\"nuc\":\"max\",\"mem\":\"max\",\"gfp\":\"mean\"}\n                    vmin, vmax = control.get_optimal_seg_contrast(gene)\n                    proj.set_vmin_vmax_gfp_values(vmin, vmax)\n                else: #raw data\n                    mode = {\"nuc\":\"max\",\"mem\":\"max\",\"gfp\":\"max\"}\n                    vmin, vmax = control.get_optimal_raw_contrast(gene)\n                    if gene in special_raw_contrast:\n                        vmin, vmax = special_raw_contrast[gene]\n                    proj.set_vmin_vmax_gfp_values(vmin, vmax)\n                proj.set_projection_mode(ax=\"z\", mode=mode)\n                proj.compute()\n                pz = proj.projs[\"gfp\"].copy()\n                contourz = proj.get_proj_contours()\n                proj.set_projection_mode(ax=\"y\", mode=mode)\n                proj.compute()\n                py = proj.projs[\"gfp\"].copy()\n                contoury = proj.get_proj_contours()\n                im = np.concatenate([py[yyi:yyf, :], pz[yzi:yzf, :]], axis=0)\n                cmap = \"binary\" if ch else \"gray\"\n                ax.imshow(im, cmap=cmap, origin=\"lower\", vmin=proj.gfp_vmin, vmax=proj.gfp_vmax)\n                for alias_cont, alias_color in zip([\"nuc\", \"mem\"], [\"cyan\", \"magenta\"]):\n                    [ax.plot(c[:,1], c[:,0]-yyi, lw=0.5, color=alias_color) for c in contoury[alias_cont]]\n                    [ax.plot(c[:,1], c[:,0]+(yyf-yyi)-yzi, lw=0.5, color=alias_color) for c in contourz[alias_cont]]\n                ax.set_xlim(0, im.shape[1])\n                ax.set_ylim(0, im.shape[0])\n            plt.savefig(f\"{file_prefix}_{chname}_{ncell}\", dpi=300)\n            plt.show()\n\ndef contact_sheet_params(box_size, ylow=110, zlow=70):\n    bbox = box_size\n    # z/y chop factors\n    yyi, yzi = ylow, zlow\n    yyf, yzf = bbox-yyi, bbox-yzi\n    # cell and nuc masks\n    yx = (bbox-(yyf-yyi)+bbox-(yzf-yzi))/bbox\n    figargs = {\"gridspec_kw\": {\"hspace\": 0}, \"sharex\": True}\n    return (yyi, yyf, yzi, yzf), bbox, figargs\n\ndef load_single_cell_image(params):\n    row = params[\"row\"]\n    if params[\"redirect\"]:\n        row = redirect_single_cell_path(row)\n    producer = io.DataProducer(params[\"control\"])\n    producer.set_row(row)\n    producer.load_single_cell_data()\n    data = producer.data\n    if params[\"alignment\"]:\n        producer.align_data(force_alignment=True)\n        data = producer.data_aligned\n    return row.name, data\n\n\ndef load_multiple_single_cell_images_fast(selection, df, control, channels=[3,4,2,7], redirect=False, alignment=True):\n    data = {}\n    for gene, CellIds in selection.items():\n        params = [{\n            \"row\": df.loc[CellId],\n            \"redirect\": redirect,\n            \"control\": control,\n            \"alignment\": alignment\n        } for CellId in CellIds]\n        with concurrent.futures.ProcessPoolExecutor(control.get_ncores()) as executor:\n            celldata = list(tqdm(executor.map(load_single_cell_image, params), total=len(params), leave=False))\n        data[gene] = [{\"CellId\": idx, \"img\": img[channels]} for idx, img in celldata]\n    return data\n\ndef load_multiple_single_cell_images(selection, df, control, channels=[3,4,2,7], redirect=False, check_channels_only=False):\n    data = {}\n    for gene, CellIds in selection.items():\n        producers = []\n        for CellId in CellIds:\n            row = df.loc[CellId]\n            if redirect:\n                row = redirect_single_cell_path(row)\n            producer = io.DataProducer(control)\n            producer.set_row(row)\n            producer.load_single_cell_data()\n            producer.align_data()\n            producers.append((CellId, producer))\n            if check_channels_only:\n                print(f\"Available channels: {[f'{i}-{ch}' for i, ch in enumerate(producer.channels)]}\")\n                return None\n        data[gene] = [{\"CellId\": i, \"img\": p.data_aligned[[3, 4, 2, 7]]} for i, p in producers]\n    return data\n\ndef get_reps_from_lda_walk(pca_lda, mps):\n    pcs_back = pca_lda[\"lda\"].walk(mps)#, limit_to_range=lda_values, return_map_points=True)\n    pcs_back *= pca_lda[\"stds\"].values\n    pcs_back = pd.DataFrame(pcs_back, columns=[f\"PC{i}\" for i in range(1,1+pca_lda[\"npcs\"])])\n    reps_back = pca_lda[\"pca\"].inverse_transform(pcs_back).reshape(len(mps), 65, -1)\n    return reps_back\n\ndef make_lda_histogram(df, ax, xmin=-3, xmax=3, ymax=2.1, ratio=1.0, verbose=True):\n    edges = np.linspace(xmin, xmax, 1+int((xmax-xmin)/0.5))\n    for color, (g, df_group) in zip([\"black\",\"#FF3264\"], df.groupby(\"Dataset\")):\n        ax.hist(df_group.LDA, bins=edges, histtype=\"step\", color=color, density=True, lw=2)\n        ax.plot([df_group.LDA.mean(), df_group.LDA.mean()], [0, 0.9*ymax], color=color, lw=1, ls=\"--\", zorder=1e10)\n#         ax.axvline(x=df_group.LDA.mean(), ymin=0, ymax=0.5*ymax, color=color, lw=1, linestyle=\"--\", zorder=1e10)\n        if verbose:\n            print(g, df_group.LDA.mean())\n    ax.set_xlim(xmin, xmax)\n\n    ax.set_ylim(0, ymax)\n    xleft, xright = ax.get_xlim()\n    ybottom, ytop = ax.get_ylim()\n    ax.set_aspect(abs((xright-xleft)/(ybottom-ytop))*ratio)\n\n    ax.axes.get_yaxis().set_visible(False)\n    sigmas = np.linspace(-2, 2, 5)\n    ax.set_xticks(sigmas, [f\"{int(s)}$\\sigma$\" for s in sigmas])\n    ax.tick_params(axis=\"x\", which='major', labelsize=8)\n\n    ax2 = ax.secondary_xaxis(\"top\")\n    ax2.tick_params(axis=\"x\", direction=\"in\")\n    ax2.set_xticks(sigmas, [\"\" for s in sigmas])\n\n    return\n\ndef run_lda_analysis(df_map, managers, return_pca_lda_objs=False):\n    \n    dsname = [ds for ds in df_map.index.get_level_values(\"dataset\").unique() if ds != \"base\"][0]\n    print(f\"Running dataset: {dsname}\")\n    \n    pca_lda = {}\n    for gene in df_map.index.get_level_values(\"structure_name\").unique().values:#control.get_gene_names():\n\n        df_gene = df_map.loc[(dsname, gene)]\n\n        CellIds_pt = df_gene.index.values\n        CellIds_ct = df_gene.NNCellId.unique()\n\n        rloader_ct = RepsSharedMemoryLoader(managers[\"control\"][\"control\"])\n        rloader_pt = RepsSharedMemoryLoader(managers[\"perturbed\"][\"control\"])\n        reps_ct = rloader_ct.load(CellIds_ct).astype(np.uint8)\n        reps_pt = rloader_pt.load(CellIds_pt).astype(np.uint8)\n        print(f\"mean rep: ct={reps_ct.mean()}, ({len(CellIds_ct)}), pt={reps_pt.mean()}, ({len(CellIds_pt)})\")\n        '''\n        CellIds_ct, reps_ct = get_all_parameterized_intensity_of_seg_channel(CellIds_ct, managers[\"control\"][\"device\"])\n        CellIds_pt, reps_pt = get_all_parameterized_intensity_of_seg_channel(CellIds_pt, managers[\"perturbed\"][\"device\"])\n        print(f\"mean rep: ct={reps_ct.mean()}, ({len(CellIds_ct)}), pt={reps_pt.mean()}, ({len(CellIds_pt)})\")\n        '''\n        reps = np.concatenate([reps_ct, reps_pt], axis=0)\n        vsize = int(sys.getsizeof(reps)) / float(1 << 20)\n\n        npcs = np.min([32, reps.shape[0]-1])\n        pca = PCA(npcs, svd_solver=\"full\")\n        pca = pca.fit(reps)\n        axes = pca.transform(reps)\n        axes = pd.DataFrame(axes, columns=[f\"PC{i}\" for i in range(1, 1+npcs)])\n\n        groups = np.array([0]*len(CellIds_ct) + [1]*len(CellIds_pt))\n        stds = axes.std(axis=0)\n        axes /= stds\n        axes, pca = sort_pcs(axes, groups, pca)\n        axes[\"Dataset\"] = groups\n        axes[\"CellId\"] = CellIds_ct.tolist() + CellIds_pt.tolist()\n        axes = axes.set_index([\"Dataset\", \"CellId\"])\n\n        lda = SimpleBinaryLDA()\n        lda = lda.sfit(axes.values, groups)\n        lda_values = lda.transform(axes.values).flatten()\n        axes[\"LDA\"] = lda_values\n\n        pca_lda[gene] = axes        \n        if return_pca_lda_objs:\n            pca_lda[gene] = {\"axes\": axes, \"pca\": pca, \"stds\": stds, \"npcs\": npcs, \"lda\": lda}\n\n    return pca_lda\n\ndef find_cells_nearest_the_mean_of_the_two_populations(pca_lda, ncells=15):\n    CellIds = {}\n    for gene, axes in pca_lda.items():\n        idxs = []\n        for ds, df_group in axes.groupby(level=\"Dataset\"):\n            dist = np.abs(df_group.LDA-df_group.LDA.mean())\n            dist_rank = np.argsort(dist).tolist()\n            idxs += df_group.index[dist_rank][:ncells].tolist()\n        CellIds[gene] = idxs\n    return CellIds\n\ndef resize_and_group_images_grays(imgs, offset=0):\n    bbox = np.array([im.shape for im in imgs]).max(axis=0)[1:]\n    rad = np.max([offset, bbox.max()])\n    for i, im in enumerate(imgs):\n        shape = im.shape[1:]\n        pad = [int(0.5*(rad-s)) for s in shape]\n        pad = [(0,0)]+[(p, int(rad-s-p)) for (s, p) in zip(shape, pad)]\n        imgs[i] = np.pad(im, pad, mode=\"constant\", constant_values=255)\n    imgs = np.array(imgs)\n    return imgs\n\ndef resize_and_group_images(imgs, offset=0):\n    bbox = np.array([im.shape for im in imgs]).max(axis=0)[:-1]\n    rad = np.max([offset, bbox.max()])\n    for i, im in enumerate(imgs):\n        shape = im.shape[:-1]\n        pad = [int(0.5*(rad-s)) for s in shape]\n        pad = [(p, int(rad-s-p)) for (s, p) in zip(shape, pad)]+[(0,0)]\n        imgs[i] = np.pad(im, pad, mode=\"constant\", constant_values=255)\n    imgs = np.array(imgs)\n    return imgs\n\ndef now(text):\n    print(text, datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n\ndef redirect_single_cell_path(row_input):\n    row = row_input.copy()\n    # redirecting the path to seg images bc some files are corrupted (fixme before resubmission)\n    subpath_old = \"projects/cvapipe_analysis\"\n    subpath_new = \"datasets/hpisc_single_cell/variance\"\n    row.crop_seg = row.crop_seg.replace(subpath_old, subpath_new)\n    return row\n\nclass Masker():\n    colors = [\n        (255/255., 255/255., 255/255.),\n        (100/255., 149/255., 237/255.),\n        (128/255., 128/255., 0/255.),\n        (240/255., 128/255., 128/255.),\n        (200/255., 200/255., 200/255.),\n        (200/255., 200/255., 200/255.),\n        (200/255., 200/255., 200/255.),\n        (200/255., 200/255., 200/255.)\n    ]\n    patterns = [(1,1,1), (0,1,1), (1,0,1), (1,0,0), (0,1,0), (0,0,1), (1,1,0)]\n\n    def __init__(self, control):\n        self.control = control\n\n    def set_data(self, masks, data, colnames=None):\n        '''data must be a MxSxF binary matrix, where\n        M is the number of masks, S is the number of\n        samples and F is the number of features. M\n        must match the length of elements of patterns\n        colors hardcoded above. Data must have same\n        shape but of type float.'''\n        self.colnames = colnames\n        self.data = self.fix_format(data)\n        self.masks = self.fix_format(masks)\n        \n    def execute(self):\n        self.create_groups()\n        self.levels = self.create_levels_from_continous_data(self.data)\n        self.combine_levels(replace_nan=0)\n\n    def create_groups(self):\n        groups = np.ones(self.masks.shape[1:], dtype=int)\n        for pid, pattern in enumerate(self.patterns):\n            matches = [pattern[c]==value for c, value in enumerate(self.masks)]\n            matches = np.logical_and.reduce(matches)\n            groups[np.where(matches)] = 2+pid # group = 1 means no hit\n        self.groups = groups\n\n    def combine_levels(self, replace_nan=-1):\n        levels = self.levels.astype(np.float32)\n        for c, mask in enumerate(self.masks):\n            levels[c,~mask] = np.nan\n        levels = np.nanmin(levels, axis=0)\n        if replace_nan > -1:\n            levels[np.where(np.isnan(levels))] = replace_nan\n            levels = levels.astype(int)\n        self.combined_levels = levels\n\n    def get_result_as_dataframes_and_cmap(self, ignore_confidence=True):\n        genes = self.control.get_gene_names()\n        colnames = genes if self.colnames is None else self.colnames\n        dfgrp = pd.DataFrame(self.groups, index=genes, columns=colnames)\n        dflvl = pd.DataFrame(self.combined_levels, index=genes, columns=colnames)\n        cmap = [(k+1,v) for k, v in enumerate(self.colors)]\n        lvls = np.unique(dflvl.values.flatten())\n        dflvl.replace(dict([(v,lvls.max()) for v in lvls]), inplace=True)\n        return dfgrp, dflvl, dict(cmap)\n\n    @staticmethod\n    def fix_format(x):\n        if x.ndim==2:\n            return x.reshape(1,*x.shape)\n        return x\n        \n    @staticmethod\n    def create_levels_from_continous_data(x, bins=[-np.inf,0.05,0.25,np.inf], labels=[7, 4, 1]):\n        levels = pd.cut(x.flatten(), bins=bins, labels=labels).tolist()\n        return np.array(levels).reshape(*x.shape)\n\n    @staticmethod\n    def reduce_to_diag(xs, swap_axs=False):\n        d = np.array([np.diag(x) for x in xs]).T\n        d = d.reshape(1,*d.shape)\n        if swap_axs:\n            d = np.swapaxes(d, 0, -1)\n        return d\n    \nclass CorrTable:\n    \n    def __init__(self, control):\n        \n        self.cols = []\n        self.precision = 3\n        self.control = control\n        self.phenos = [\"ct\", \"pt\"]\n        self.aliases = [\"M1M2\", \"M3\"]\n        self.data_folder = f\"{control.get_staging()}/concordance/plots/\"\n        self.filters = {\"Corr\": (\"gt\",0.03), \"Delta\": (\"gt\",0.02), \"Swap\": (\"lt\",0.05), \"ABSpct\": (\"gt\", 0.2), \"Pct\": (\"gt\", 0.2)}\n        path_cvapipe = Path(control.get_staging()).parent\n        self.datasets = {\n            \"M1M2\": {\n                \"ct\": f\"{path_cvapipe}/local_staging_variance_m1m2\",\n                \"pt\": f\"{path_cvapipe}/local_staging_m1m2\"\n            },\n            \"M3\": {\n                \"ct\": f\"{path_cvapipe}/local_staging_variance_m3\",\n                \"pt\": f\"{path_cvapipe}/local_staging_m3\"\n            }\n        }\n        self.comparisons = {\n            \"Control vs. M1M2\": [(\"M1M2\", \"ct\"), (\"M1M2\", \"pt\")],\n            \"M1M2 vs. M3\": [(\"M1M2\", \"pt\"), (\"M3\", \"pt\")],\n            \"Control vs. M3\": [(\"M3\", \"ct\"), (\"M3\", \"pt\")]\n        }\n\n        self.load_correlations()\n        self.load_swaps()\n        self.make_dataframe()\n        self.calculate_deltas()\n#         self.calculate_pct_change()\n\n    def get_unique_combinations_of_comparisons(self):\n        df = pd.DataFrame([])\n        for _, ((a1, p1), (a2, p2)) in self.comparisons.items():\n            for a, p in zip([a1, a2], [p1, p2]):\n                df = df.append({\"alias\": a, \"phenotype\": p}, ignore_index=True)\n        return df.drop_duplicates().reset_index(drop=True)\n\n    def load_correlations(self):\n        for _, comb in self.get_unique_combinations_of_comparisons().iterrows():\n            path = Path(self.datasets[comb.alias][comb.phenotype]) / \"concordance\"\n            control, dev = get_managers_from_step_path(path)\n            variables = control.get_variables_values_for_aggregation()\n            df_agg = shapespace.ShapeSpaceBasic.get_aggregated_df(variables)\n            df_agg = df_agg.drop(columns=[\"structure\"]).drop_duplicates().reset_index(drop=True)\n            df, _ = dev.get_mean_correlation_matrix_of_reps(df_agg.loc[0])\n            col = self.df_to_col(df, col_name=f\"Corr_{comb.alias}_{comb.phenotype}\")\n            self.cols.append(col)\n                \n    def load_swaps(self):\n        for _, ((a1, p1), (a2, p2)) in self.comparisons.items():\n            sufix = f\"{a1}_{p1}_{a2}_{p2}\"\n            fname = f\"../SwapCalculation/swap_{sufix}.csv\"\n            try:\n                df = pd.read_csv(fname, index_col=0)\n            except:\n                print(f\"WARNING: No swap found for {sufix}\")\n                return\n            name = f\"Swap_{sufix}\"\n            col = self.df_to_col(df, col_name=name)\n            self.cols.append(col)\n                        \n    def make_dataframe(self):\n        df = pd.DataFrame(self.cols).T\n        df = df.dropna(axis=1, how=\"all\")\n        self.df = df\n    \n    def calculate_deltas(self):\n        for _, ((a1, p1), (a2, p2)) in self.comparisons.items():\n            name1 = f\"Corr_{a1}_{p1}\"\n            name2 = f\"Corr_{a2}_{p2}\"\n            name = f\"Delta_{a1}_{p1}_{a2}_{p2}\"\n            self.df[name] = self.df[name1]-self.df[name2]\n\n    def calculate_pct_change(self):\n        for _, ((a1, p1), (a2, p2)) in self.comparisons.items():\n            name1 = f\"Corr_{a1}_{p1}\"\n            name2 = f\"Corr_{a2}_{p2}\"\n            name = f\"Pct_{a1}_{p1}_{a2}_{p2}\"\n            self.df[name] = (self.df[name1]-self.df[name2])/self.df[name1]\n            name = f\"ABSpct_{a1}_{p1}_{a2}_{p2}\"\n            self.df[name] = (self.df[name1]-self.df[name2]).abs()/self.df[name1]\n\n    def round_values(self):\n        self.df = self.df.round(decimals=self.precision)\n            \n    def apply_filters(self, metrics, cast=True, replace_with_nan=False):\n        if cast:\n            self.round_values()\n        for col in self.df.columns:\n            for name, (comp, thresh) in self.filters.items():\n                if name in col:\n                    values = self.df[col].abs()\n                    values = values > thresh if comp==\"gt\" else values < thresh\n                    self.df[f\"{col}_valid\"] = values\n        self.df = self.df[sorted(self.df.columns)]\n        \n        for cid, (comp_name, ((a1, p1), (a2, p2))) in enumerate(self.comparisons.items()):\n            checks = {}\n            checks[\"Corr\"] = self.df[f\"Corr_{a1}_{p1}_valid\"]\n            checks[\"Delta\"] = self.df[f\"Delta_{a1}_{p1}_{a2}_{p2}_valid\"]\n            checks[\"Swap\"] = self.df[f\"Swap_{a1}_{p1}_{a2}_{p2}_valid\"]\n#             checks[\"Pct\"] = self.df[f\"Pct_{a1}_{p1}_{a2}_{p2}_valid\"]\n#             checks[\"ABSpct\"] = self.df[f\"ABSpct_{a1}_{p1}_{a2}_{p2}_valid\"]\n            checks = [v.values for k, v in checks.items() if k in metrics]\n            checks = np.prod(checks, axis=0).astype(bool)\n            self.df[comp_name] = checks\n            if replace_with_nan:\n                if \"Delta\" in metrics:\n                    self.df.loc[checks==False, [f\"Delta_{a1}_{p1}_{a2}_{p2}\"]] = np.nan\n#                 if \"Pct\" in metrics:\n#                     self.df.loc[checks==False, [f\"Pct_{a1}_{p1}_{a2}_{p2}\"]] = np.nan\n#                 if \"ABSpct\" in metrics:\n#                     self.df.loc[checks==False, [f\"ABSpct_{a1}_{p1}_{a2}_{p2}\"]] = np.nan\n\n    def cluster(self, cols, thresh=0.2, show=False):\n        X = self.df[cols].values\n        Z = spcluster.hierarchy.linkage(X, \"average\")\n        if show:\n            fig, ax = plt.subplots(1, 1, figsize=(32, 16))\n            _ = spcluster.hierarchy.dendrogram(\n                Z, labels=self.get_indices_as_strings(self.df), leaf_rotation=90\n            )\n            ax.set_ylim(-0.1, 1.5)\n            plt.tight_layout()\n            plt.show()\n        self.df[\"Cluster\"] = spcluster.hierarchy.fcluster(Z, t=thresh, criterion=\"distance\")\n\n    def get_columns_to_display(self):\n        cols = [\"Cluster\"] + [k for k in self.comparisons.keys()]\n        for p in self.phenos:\n            for a in self.aliases:\n                cols.append(f\"Corr_{a}_{p}\")\n        for s in [\"Delta\", \"Swap\"]:#, \"Pct\", \"ABSpct\"]:\n            for _, ((a1, p1), (a2, p2)) in self.comparisons.items():\n                cols.append(f\"{s}_{a1}_{p1}_{a2}_{p2}\")\n        return cols\n        \n    def get_df(self, remove_symm=False, group=None, return_col_names=False):\n        cols = self.get_columns_to_display()\n        df = self.df.copy()\n        if group is not None:\n            df[\"flag\"] = True\n            for cid, cval in enumerate(group):\n                df.flag = df.flag * ((df[f\"Comp{cid}\"]==cval))\n            df = df.loc[df.flag==True]\n        df = df[cols]\n        if remove_symm:\n            df = self.remove_rows_with_symmetric_indices(df)\n            \n        SCols = [\"S1\", \"S2\"]\n        df.index.set_names(SCols, inplace=True)\n        df = df.reset_index()\n        for col in SCols:            \n            df[col] = pd.Categorical(df[col].values, categories=self.control.get_gene_names(), ordered=True)\n        df = df.sort_values(by=[\"Cluster\", \"S1\", \"S2\"])\n        cols = df.columns.tolist()\n        df = df[[\"Cluster\"]+[col for col in cols if col != \"Cluster\"]]\n        if return_col_names:\n            bcols = [f for f in self.comparisons.keys()]\n            ccols = [f for f in df.columns if \"Corr\" in f]\n            dcols = [f for f in df.columns if \"Delta\" in f]\n            scols = [f for f in df.columns if \"Swap\" in f]\n        return df, (bcols, ccols, dcols, scols)\n    \n    @staticmethod\n    def get_indices_as_strings(df):\n        return [f\"{s1}-{s2}\" for (s1, s2) in df.index]\n    \n    @staticmethod\n    def remove_rows_with_symmetric_indices(df):\n        df[\"flag\"] = False\n        for s1, s2 in df.index:\n            if (s1==s2) | df.at[(s1, s2), \"flag\"]:\n                continue\n            if (s2, s1) in df.index:\n                df.at[(s2, s1), \"flag\"] = True\n        df = df.loc[df.flag==False].drop(columns=[\"flag\"])\n        return df\n    \n    @staticmethod\n    def read_df(path, icol=0):\n        try:\n            df = pd.read_csv(path, index_col=icol)\n        except:\n            return pd.DataFrame([])\n        \n        if \"self\" in df.columns:\n            df = df.drop(columns=[\"self\"])\n        return df\n    \n    @staticmethod\n    def df_to_col(df, col_name):\n        col = df.unstack()\n        col.name = col_name\n        return col\n    \n    @staticmethod\n    def convert_swap_into_ci_levels(swapmx, labels=[7, 4, 1]):\n        levels = []\n        for c in range(swapmx.shape[1]):\n            x = pd.cut(swapmx[:, c], bins=[-np.inf,0.05,0.25,np.inf], labels=labels).tolist()\n            levels.append(x)\n        levels = np.array(levels).T\n        return levels\n    \ndef save_html_table(df, columns, table, filename):\n    comp_cols, corr_cols, delta_cols = columns[:3]\n    html = df.style\\\n    .background_gradient(\"tab20\", axis=0, subset=[\"Cluster\"])\\\n    .applymap(lambda v: f\"background-color: {table.control.get_gene_color(v)}\", subset=[\"S1\"])\\\n    .background_gradient(\"Greys\", vmin=0, vmax=1, axis=0, subset=comp_cols)\\\n    .background_gradient(\"PRGn\", vmin=-0.1, vmax=0.1, axis=1, subset=delta_cols)\\\n    .background_gradient(\"seismic\", vmin=-0.2, vmax=0.2, axis=1, subset=corr_cols)\\\n    .applymap(lambda v: 'opacity: 20%;' if (np.abs(v)<=table.filters[\"Delta\"][-1]) else None, subset=delta_cols)\\\n    .applymap(lambda v: 'opacity: 20%;' if (np.abs(v)<=table.filters[\"Corr\"][-1]) else None, subset=corr_cols)\\\n    .format(na_rep=\".\", precision=3).highlight_null('white')\\\n    .set_table_styles([dict(selector=\"th\",props=[('max-width', '30px')]), dict(selector=\"th.col_heading\", props=[('transform', 'rotateZ(-90deg)'), ('height', '180px')])])\\\n    .to_html()\n    with open(filename,'w') as f:\n        f.write(html)\n#     .background_gradient(\"PRGn\", vmin=0, vmax=2, axis=1, subset=pct_cols)\\\n#     .background_gradient(\"PRGn\", vmin=-2, vmax=2, axis=1, subset=abspct_cols)\\\n#   .applymap(lambda v: 'opacity: 20%;' if (np.abs(v)<=table.filters[\"Pct\"][-1]) else None, subset=abspct_cols)\\\n#     .applymap(lambda v: 'opacity: 20%;' if (np.abs(v)<=table.filters[\"ABSpct\"][-1]) else None, subset=pct_cols)\\\n    \nclass SwapCalculator():\n    \n    def __init__(self, config):\n        self.setup_comparisons(config)\n        self.load_agg_correlation_data()\n        \n    def setup_comparisons(self, config):\n        '''Paths to the matched datasets. ct and pt refer to control\n        and perturbed datasets. Below we specify the combinations\n        of tests we want to perform. The combinations are specified\n        using a name, then a pair of tuples. Each tuple must include\n        a matched-dataset name and condition (ct or pt).'''\n        path_cvapipe = Path(config[\"project\"][\"local_staging\"]).parent\n        self.datasets = {\n            \"M1M2\": {\n                \"ct\": f\"{path_cvapipe}/local_staging_variance_m1m2\",\n                \"pt\": f\"{path_cvapipe}/local_staging_m1m2\"\n            },\n            \"M3\": {\n                \"ct\": f\"{path_cvapipe}/local_staging_variance_m3\",\n                \"pt\": f\"{path_cvapipe}/local_staging_m3\"\n            }}\n\n        self.comparisons = {\n            \"ControlM1M2 vs. M1M2\": [(\"M1M2\", \"ct\"), (\"M1M2\", \"pt\")],\n            \"M1M2 vs. M3\": [(\"M1M2\", \"pt\"), (\"M3\", \"pt\")],\n            \"ControlM3 vs. M3\": [(\"M3\", \"ct\"), (\"M3\", \"pt\")],\n            \"ControlM1M2 vs. ControlM3\": [(\"M1M2\", \"ct\"), (\"M3\", \"ct\")]\n        }\n\n    def get_unique_combinations_of_comparisons(self):\n        df = pd.DataFrame([])\n        for _, ((a1, p1), (a2, p2)) in self.comparisons.items():\n            for a, p in zip([a1, a2], [p1, p2]):\n                df = df.append({\"alias\": a, \"phenotype\": p}, ignore_index=True)\n        return df.drop_duplicates().reset_index(drop=True)\n    \n    def load_agg_correlation_data(self):\n        '''Loads the correlation matrix for each pair (alias, condition)\n        as well as the number of cells used to calculate the correlations.'''\n        data = []\n        for _, comb in self.get_unique_combinations_of_comparisons().iterrows():\n            path = Path(self.datasets[comb.alias][comb.phenotype]) / \"concordance\"\n            control, dev = get_managers_from_step_path(path)\n            variables = control.get_variables_values_for_aggregation()\n            df_agg = shapespace.ShapeSpaceBasic.get_aggregated_df(variables)\n            df_agg = df_agg.drop(columns=[\"structure\"]).drop_duplicates().reset_index(drop=True)\n            for _, row in df_agg.iterrows():\n                df_corr, prefix, df_size = dev.get_mean_correlation_matrix_of_reps(row, return_ncells=True)\n                dfs = {\"corr\": df_corr, \"size\": df_size}\n                data.append((comb.alias, comb.phenotype, prefix, dfs))\n        self.data = dict()\n        for k1, k2, k3, value in data:\n            self.data.setdefault(k1, {}).setdefault(k2, {}).update({k3: value})\n\n    def set_df_of_error_curves(self, df, colname):\n        self.colname = colname\n        self.df_error = df.copy()        \n\n    def calculate_swaps(self, a1, p1, a2, p2):\n        '''By defining the prefix as below we are explicitly using the fact\n        that matched-datasets have been processed using a single shape mode\n        binned in a single bin.'''\n        np.random.seed(42)\n        prefix = [k for k in self.data[a1][p1].keys()][0]\n        genes = self.data[a1][p1][prefix][\"corr\"].index\n        df_swap = pd.DataFrame(0, index=genes, columns=genes)\n        for gid1, gene1 in tqdm(enumerate(genes), total=len(genes), leave=False):\n            for gid2, gene2 in enumerate(genes):\n                if gid2 >= gid1:\n                    n11 = self.data[a1][p1][prefix][\"size\"].at[gene1, \"ncells\"]\n                    n12 = self.data[a1][p1][prefix][\"size\"].at[gene2, \"ncells\"]\n                    n21 = self.data[a2][p2][prefix][\"size\"].at[gene1, \"ncells\"]\n                    n22 = self.data[a2][p2][prefix][\"size\"].at[gene2, \"ncells\"]\n                    n1 = np.min([n11, n12])#int(0.5*(n11+n12))\n                    n2 = np.min([n21, n22])#int(0.5*(n21+n22))\n                    corr1 = self.data[a1][p1][prefix][\"corr\"].at[gene1, gene2]\n                    corr2 = self.data[a2][p2][prefix][\"corr\"].at[gene1, gene2]\n                    ratio1 = self.get_ratio(gene1, gene2, n1)\n                    ratio2 = self.get_ratio(gene1, gene2, n2)\n                    scale1 = np.abs(corr1)*(ratio1-1)\n                    scale2 = np.abs(corr2)*(ratio2-1)\n                    swap = self.bootstrap(corr1, scale1, corr2, scale2)\n                    df_swap.loc[gene1, gene2] = df_swap.loc[gene2, gene1] = swap\n        return df_swap\n\n    def get_ratio(self, gene1, gene2, n):\n        '''Remove 1 from the ratio to get a proxy for the variation\n        around the true value. Limiting scale to 0 in case it goes\n        negative due to stochastic fluctuations.'''\n        n = 400 if n > 400 else n\n        index = (gene1, gene2, n)\n        if index in self.df_error.index:\n            return np.max([1, self.df_error.at[index, self.colname]])\n        return np.max([1, self.df_error.at[(gene2, gene1, n), self.colname]])\n\n    @staticmethod\n    def bootstrap(x1, scale1, x2, scale2):\n        NRUNS = 10000\n        x1_new = np.random.normal(loc=x1, scale=scale1, size=NRUNS)\n        x2_new = np.random.normal(loc=x2, scale=scale2, size=NRUNS)\n        count = np.logical_xor(x1>=x2, x1_new>=x2_new)\n        return count.sum()/NRUNS\n\n    @staticmethod\n    def expdist(m, s):\n        x = np.linspace(m-4*s, m+4*s, 64)\n        y = np.exp(-0.5*((x-m)/s)**2)\n        y /= y.sum()\n        return x, y\n\n    def visualize_distributions_for(self, gene1, gene2):\n        nc = len(self.comparisons)\n        fig, axs = plt.subplots(1,nc, figsize=(3*nc,1.5))\n        xmin, xmax = [], []\n        for ax, (_, ((a1, p1), (a2, p2))) in zip(axs, self.comparisons.items()):\n            prefix = [k for k in self.data[a1][p1].keys()][0]\n            m1 = self.data[a1][p1][prefix][\"corr\"].loc[gene1, gene2]\n            n11 = self.data[a1][p1][prefix][\"size\"].at[gene1, \"ncells\"]\n            n12 = self.data[a1][p1][prefix][\"size\"].at[gene2, \"ncells\"]\n            m2 = self.data[a2][p2][prefix][\"corr\"].loc[gene1, gene2]\n            n21 = self.data[a2][p2][prefix][\"size\"].at[gene1, \"ncells\"]\n            n22 = self.data[a2][p2][prefix][\"size\"].at[gene2, \"ncells\"]\n            n1 = np.min([n11, n12])\n            n2 = np.min([n21, n22])\n            r1 = self.get_ratio(gene1, gene2, n1)\n            r2 = self.get_ratio(gene1, gene2, n2)\n            x1, y1 = SwapCalculator.expdist(m1, m1*(r1-1))\n            ax.plot(x1, y1)\n            x2, y2 = SwapCalculator.expdist(m2, m2*(r2-1))\n            ax.plot(x2, y2)\n            xmin.append(np.min([x1, x2]))\n            xmax.append(np.max([x1, x2]))\n            ax.set_title(f\"{a1}_{p1} vs. {a2}_{p2}\\n{m1:.3f} ({n1}), {m2:.3f} ({n2})\")\n        for axi, ax in enumerate(axs):\n            if not axi:\n                ax.set_ylabel(f\"{gene1}-{gene2}\", fontsize=14)\n            ax.set_xlim(np.min(xmin), np.max(xmax))\n        plt.show()\n    \n    def execute(self):\n        dfs = {}\n        for _, ((a1, p1), (a2, p2)) in self.comparisons.items():\n            df_swap = self.calculate_swaps(a1, p1, a2, p2)\n            dfs[f\"{a1}_{p1}_{a2}_{p2}\"] = df_swap\n        return dfs\n    \nclass RepsSharedMemoryReader(io.LocalStagingIO):\n    \n    rep_length = 532610\n    \n    def __init__(self, control, shm_id):\n        self.shm_id = shm_id\n        super().__init__(control)\n\n    def read_representation_as_boolean(self, eindex):\n        i, index = eindex\n        rep = self.read_parameterized_intensity_of_alias(index, \"STR\").astype(bool).flatten()\n        if rep is not None:\n            ptr_reps = smem.SharedMemory(name=self.shm_id)\n            shm_reps = np.ndarray((self.ncells, self.rep_length), dtype=bool, buffer=ptr_reps.buf)\n            shm_reps[i] = rep\n            #ptr_reps.close()\n            #ptr_reps.unlink()\n        return\n\n    def load(self, CellIds):\n        self.CellIds = CellIds\n        self.ncells = len(CellIds)\n        func = self.read_representation_as_boolean\n        with tqdm(total=self.ncells, leave=False) as pbar:\n            with concurrent.futures.ProcessPoolExecutor(self.control.get_ncores()) as executor:\n                futures = {executor.submit(func, eid): eid for eid in enumerate(self.CellIds)}\n                for _ in concurrent.futures.as_completed(futures):\n                    pbar.update(1)\n                    \nclass RepsSharedMemoryLoader():\n    def __init__(self, control):\n        self.shm_id = uuid.uuid4().hex[:8]\n        self.loader = RepsSharedMemoryReader(control, self.shm_id)\n        \n    def load(self, CellIds):\n        ncells = len(CellIds)\n        reps = np.zeros((ncells, RepsSharedMemoryReader.rep_length), dtype=bool)\n        ptr_reps = smem.SharedMemory(create=True, size=reps.nbytes, name=self.shm_id)\n        shm_reps = np.ndarray(reps.shape, dtype=reps.dtype, buffer=ptr_reps.buf)\n        shm_reps[:] = reps[:]\n        #ptr_reps.close()\n        #ptr_reps.unlink()\n        self.loader.load(CellIds)\n        reps[:] = shm_reps[:]\n        return reps\n\ndef get_all_parameterized_intensity_of_seg_channel(CellIds, device):\n#     raise ValueError(\"Function deprecated. Please use RepsSharedMemoryLoader\")\n    ncores = multiprocessing.cpu_count()\n    idsch = zip(*[(i,\"STR\") for i in CellIds])\n    with concurrent.futures.ProcessPoolExecutor(ncores) as executor:\n        reps = list(tqdm(\n            executor.map(device.read_parameterized_intensity_of_alias, *idsch), leave=False, total=len(CellIds)\n        ))\n    reps = [(i, r.flatten()) for (i, r) in zip(CellIds, reps) if r is not None]\n    CellIds = np.array([i for (i, r) in reps])\n    reps = np.array([r for (i, r) in reps], dtype=bool)\n    return CellIds, reps\n\ndef sort_pcs(axes, groups, pca=None):\n    # Control (group=0) should be represented by negative.\n    # values. Remember data is centered.\n    for pcid, pc in enumerate(axes.columns):\n        if axes[pc].values[groups==0].mean() > 0:\n            axes[pc] *= -1\n            if pca is not None:\n                pca.components_[pcid] *= -1\n    return axes, pca\n\ndef get_managers_from_step_path(path):\n    with open(Path(path)/\"parameters.yaml\", \"r\") as f:\n        config = yaml.load(f, Loader=yaml.FullLoader)\n    control = controller.Controller(config)\n    device = io.LocalStagingIO(control)\n    return control, device\n\ndef setup_cvapipe_for_matched_dataset(config, dataset, step_to_use=\"preprocessing\"):\n    dsmanagers = {}\n    for pheno, path in dataset.items():\n        step_path = Path(path) / step_to_use\n        control, device = get_managers_from_step_path(step_path)\n#         config[\"project\"][\"local_staging\"] = path\n#         control = controller.Controller(config)\n#         device = io.LocalStagingIO(control)\n        dsmanagers[pheno] = {\"control\": control, \"device\": device}\n    return dsmanagers\n\ndef get_all_norm_parameterized_intensity_of_seg_channel(CellIds, device):\n    ncores = multiprocessing.cpu_count()\n    idsch = zip(*[(i,\"STR\") for i in CellIds])\n    with concurrent.futures.ProcessPoolExecutor(ncores) as executor:\n        reps = list(tqdm(\n            executor.map(device.read_normalized_parameterized_intensity_of_alias, *idsch), leave=False, total=len(CellIds)\n        ))\n    reps = [r for r in reps if r is not None]\n    reps = np.array(reps)\n    return reps\n\nclass SimpleBinaryLDA(sklda.LinearDiscriminantAnalysis):\n    def __init__(self):\n        super().__init__(solver=\"eigen\", store_covariance=True, shrinkage=\"auto\")\n    def sfit(self, X, y):\n        self.data = (X, y)\n        self.fit(X, y)\n        self.axis = np.matmul(np.linalg.inv(self.covariance_), np.diff(self.means_, axis=0).T).flatten()\n        self.centroid = X.mean(axis=0).flatten()\n        self.versor = self.axis / np.linalg.norm(self.axis)\n        self.fix_versor_orientation()\n        return self\n    def fix_versor_orientation(self):\n        dist = []\n        X, y = self.data\n        for g in [0, 1]:\n            xm = X[y==g, :].mean(axis=0)\n            dist.append(np.linalg.norm(xm-(self.centroid+self.versor)))\n        if np.argmin(dist) == 0:\n            self.versor *= -1\n    def transform(self, X):\n        lda_values = np.zeros(X.shape[0], dtype=np.float32)\n        for i, x in enumerate(X):\n            lda_values[i] = ((x-self.centroid)*self.versor).sum()\n        return lda_values\n    def display2d(self):\n        X, y = self.data\n        _, ax = plt.subplots(1,1)\n        ax.set_aspect(\"equal\")\n        for c in np.unique(y):\n            ax.scatter(X[y==c,0], X[y==c,1])\n            xo = self.centroid[0]\n            xf = self.axis[0]\n            yo = self.centroid[1]\n            yf = self.axis[1]\n        ax.plot([xo, xo+xf], [yo, yo+yf], 'k')\n        ax.plot([xo, xo-xf], [yo, yo-yf], 'k')\n        ax.scatter(xo,yo,s=50,c='k')\n        ax.plot([xo,xo+self.versor[0]], [yo,yo+self.versor[1]], lw=5, color='k')\n        ax.set_xlim(-3, 3)\n        ax.set_ylim(-3, 3)\n        plt.show()\n    def walk(self, map_points, limit_to_range=None, return_map_points=False):\n        map_points = np.array(map_points)\n        if limit_to_range is not None:\n            map_points = (map_points-map_points.min())/map_points.ptp()\n            vmin = limit_to_range.min()\n            vmax = limit_to_range.max()\n            map_points = vmin + map_points*(vmax-vmin)\n        coords = np.matmul(map_points.reshape(-1,1), self.versor.reshape(1,-1))\n        if return_map_points:\n            return coords, map_points\n        return coords\n\nclass Projector():\n    # Expects a 3 channels 3D image with following channels:\n    # 0 - nucleus (binary mask)\n    # 1 - membrane (binary mask)\n    # 2 - structure (np.float32)\n    verbose = False\n    PANEL_SIZE = 2 #Size of a matplotlib panel\n    gfp_pcts = [10, 90]\n    CMAPS = {\"nuc\": \"gray\", \"mem\": \"gray\", \"gfp\": \"inferno\"}\n\n    def __init__(self, data, force_fit=False, box_size=300, mask_on=False):\n        self.data = {\n            \"nuc\": data[0].copy().astype(bool),\n            \"mem\": data[1].copy().astype(bool),\n            \"gfp\": data[2].copy().astype(np.float32)\n        }\n        self.local_pct = False\n        self.box_size = box_size\n        self.force_fit = force_fit\n        self.bbox = self.get_bbox_of_chanel(\"mem\")\n        self.tight_crop()\n        self.pad_data()\n        self.gfp_vmin = None\n        self.gfp_vmax = None\n        if mask_on:\n            self.mask_gfp_channel()\n\n    def mask_gfp_channel(self):\n        mem = self.data[\"mem\"]\n        self.data[\"gfp\"][mem==0] = 0\n        \n    def set_verbose_on(self):\n        self.verbose = True\n        \n    def set_projection_mode(self, ax, mode):\n        # mode is a dict with keys: nuc, mem and gfp\n        self.proj_ax = ax\n        self.proj_mode = mode\n\n    def view(self, alias, ax, chopy=None):\n        proj = self.projs[alias]\n        args = {}\n        if chopy is not None:\n            proj = proj[chopy:-chopy]\n        if alias == \"gfp\":\n            args = {\"vmin\": self.gfp_vmin, \"vmax\": self.gfp_vmax}\n        return ax.imshow(proj, cmap=self.CMAPS[alias], origin=\"lower\", **args)\n        \n    def display(self, save):\n        for alias, proj in self.projs.items():\n            fig, ax = plt.subplots(1, 1, figsize=(self.PANEL_SIZE, self.PANEL_SIZE))\n            _ = self.view(alias=alias, ax=ax)\n            ax.axis(\"off\")\n            if save is not None:\n                fig.savefig(f\"{save}_{alias}.png\", dpi=150)\n            plt.show()\n\n    def get_projections(self):\n        self.projs = {}\n        ax = [\"z\", \"y\", \"x\"].index(self.proj_ax)\n        for alias, img in self.data.items():\n            if self.proj_mode[alias] == \"max\":\n                p = img.max(axis=ax)\n            if self.proj_mode[alias] == \"mean\":\n                p = img.mean(axis=ax)\n            if self.proj_mode[alias] == \"top_nuc\":\n                zc, yc, xc = [int(np.max(u)) for u in np.where(self.data[\"nuc\"])]\n                if self.proj_ax == \"z\":\n                    p = img[zc]\n                if self.proj_ax == \"y\":\n                    p = img[:, yc]\n                if self.proj_ax == \"x\":\n                    p = img[:, :, xc]\n            if self.proj_mode[alias] == \"center_nuc\":\n                zc, yc, xc = [int(np.mean(u)) for u in np.where(self.data[\"nuc\"])]\n                if self.proj_ax == \"z\":\n                    p = img[zc]\n                if self.proj_ax == \"y\":\n                    p = img[:, yc]\n                if self.proj_ax == \"x\":\n                    p = img[:, :, xc]\n            if self.proj_mode[alias] == \"center_mem\":\n                zc, yc, xc = [int(np.mean(u)) for u in np.where(self.data[\"mem\"])]\n                if self.proj_ax == \"z\":\n                    p = img[zc]\n                if self.proj_ax == \"y\":\n                    p = img[:, yc]\n                if self.proj_ax == \"x\":\n                    p = img[:, :, xc]\n            if self.proj_mode[alias] == \"max_buffer_center_nuc\":\n                buf = 3\n                zc, yc, xc = [int(np.mean(u)) for u in np.where(self.data[\"nuc\"])]\n                if self.proj_ax == \"z\":\n                    p = img[zc-buf:zc+buf].max(axis=ax)\n                if self.proj_ax == \"y\":\n                    p = img[:, yc-buf:yc+buf].max(axis=ax)\n                if self.proj_ax == \"x\":\n                    p = img[:, :, xc-buf:xc+buf].max(axis=ax)\n            if self.proj_mode[alias] == \"max_buffer_top_nuc\":\n                buf = 3\n                zc, yc, xc = [int(np.max(u)) for u in np.where(self.data[\"nuc\"])]\n                if self.proj_ax == \"z\":\n                    p = img[zc-buf:zc+buf].max(axis=ax)\n                if self.proj_ax == \"y\":\n                    p = img[:, yc-buf:yc+buf].max(axis=ax)\n                if self.proj_ax == \"x\":\n                    p = img[:, :, xc-buf:xc+buf].max(axis=ax)\n            if self.verbose:\n                print(f\"Image shape: {img.shape}, slices used: ({zc},{yc},{xc})\")\n            self.projs[alias] = p\n\n    def set_gfp_percentiles(self, pcts, local=False):\n        self.gfp_pcts = pcts\n        self.local_pct = local\n\n    def set_vmin_vmax_gfp_values(self, vmin, vmax):\n        self.gfp_vmin = vmin\n        self.gfp_vmax = vmax\n        \n    def set_gfp_colormap(self, cmap):\n        self.CMAPS[\"gfp\"] = cmap\n            \n    def calculate_gfp_percentiles(self):\n        if self.gfp_vmin is not None:\n            if self.verbose:\n                print(\"vmin/vmax values already set...\")\n            return\n        data = self.data\n        if self.local_pct:\n            data = self.projs\n        data = data[\"gfp\"][data[\"mem\"]>0]\n        self.gfp_vmin = np.percentile(data, self.gfp_pcts[0])\n        self.gfp_vmax = np.percentile(data, self.gfp_pcts[1])\n        if self.verbose:\n            print(f\"GFP min/max: {self.gfp_vmin:.3f} / {self.gfp_vmax:.3f}\")\n        \n    def compute(self, scale_bar=None):\n        self.get_projections()\n        self.calculate_gfp_percentiles()\n        if scale_bar is not None:\n            self.stamp_scale_bar(**scale_bar)\n        \n    def project(self, save=None, scale_bar=None):\n        self.compute(scale_bar=scale_bar)\n        self.display(save)\n\n    def project_on(self, alias, ax, chopy=None, scale_bar=None):\n        self.compute(scale_bar=scale_bar)\n        return self.view(alias=alias, ax=ax, chopy=chopy)\n                \n    def get_bbox_of_chanel(self, channel):\n        img = self.data[channel]\n        z, y, x = np.where(img)\n        sz, sy, sx = img.shape\n        zmin, zmax = np.max([0, np.min(z)]), np.min([sz-1, np.max(z)])\n        ymin, ymax = np.max([0, np.min(y)]), np.min([sy-1, np.max(y)])\n        xmin, xmax = np.max([0, np.min(x)]), np.min([sx-1, np.max(x)])\n        return xmin, xmax, ymin, ymax, zmin, zmax\n\n    def tight_crop(self):\n        xmin, xmax, ymin, ymax, zmin, zmax = self.bbox\n        for alias, img in self.data.items():\n            img = img[zmin:zmax+1, ymin:ymax+1, xmin:xmax+1]\n            if self.force_fit:\n                zf = np.min([ymax-ymin, self.box_size])\n                yf = np.min([ymax-ymin, self.box_size])\n                xf = np.min([xmax-xmin, self.box_size])\n                img = img[:zf, :yf, :xf]\n            self.data[alias] = img\n\n    def pad_data(self):\n        mingfp = self.data[\"gfp\"][self.data[\"mem\"]>0].min()\n        for alias, img in self.data.items():\n            shape = img.shape\n            pad = [int(0.5*(self.box_size-s)) for s in shape]\n            pad = [(p, int(self.box_size-s-p)) for (s, p) in zip(shape, pad)]\n            if np.min([np.min([i,j]) for i, j in pad]) < 0:\n                raise ValueError(f\"Box of size {self.box_size} invalid for image of size: {shape}.\")\n            self.data[alias] = np.pad(img, pad, mode=\"constant\", constant_values=0 if alias != \"gfp\" else mingfp)\n\n    def stamp_scale_bar(self, pixel_size=0.108, length=5):\n        xc = int(0.5*self.box_size)\n        n = int(length/pixel_size)\n        self.projs[\"nuc\"][20:30, xc:xc+n] = True\n\n    def get_proj_contours(self):\n        cts = {}\n        for alias in [\"nuc\", \"mem\"]:\n            im = self.projs[alias]\n            cts[alias] = skmeasure.find_contours(im, 0.5)\n        return cts\n\n    @staticmethod\n    def get_shared_morphed_max_based_on_pct_for_zy_views(instances, pct, mode, func=np.max, include_vmin_as_zero=True, nonzeros_only=True):\n        vmax = {\"z\":[], \"y\":[]}\n        for img in instances:\n            for ax in [\"z\", \"y\"]:\n                proj = Projector(img, force_fit=True)\n                proj.set_projection_mode(ax=ax, mode=mode)\n                proj.compute()\n                values = proj.projs[\"gfp\"].flatten()\n                if nonzeros_only:\n                    values = values[values>0.0]\n                if len(values) > 0:\n                    vmax[ax].append(np.percentile(values, pct))\n        if include_vmin_as_zero:\n            return dict([(ax, (0,func(vals))) for ax, vals in vmax.items()])\n        return dict([(ax, func(vals)) for ax, vals in vmax.items()])\n\n    @staticmethod\n    def get_shared_gfp_range_for_zy_views_old(instances, pcts, mode):\n        minmax = {\"z\": [], \"y\": []}\n        for k, cellinfos in instances.items():\n            for cellinfo in cellinfos:\n                img = cellinfo[\"img\"]\n                for ax in [\"z\", \"y\"]:\n                    proj = Projector(img, force_fit=True)\n                    proj.set_projection_mode(ax=ax, mode=mode)\n                    proj.compute()\n                    values = proj.projs[\"gfp\"].flatten()#[proj.projs[\"gfp\"]>0]\n                    if len(values):\n                        minmax[ax].append(np.percentile(values, pcts))\n        print(minmax)\n        return dict([(ax, (np.min(vals), np.max(vals))) for ax, vals in minmax.items()])\n    \nclass SwapCalculatorOld():\n    \n    def __init__(self, config):\n        self.setup_comparisons(config)\n        self.load_agg_correlation_data()\n        \n    def setup_comparisons(self, config):\n        '''Paths to the matched datasets. ct and pt refer to control\n        and perturbed datasets. Below we specify the combinations\n        of tests we want to perform. The combinations are specified\n        using a name, then a pair of tuples. Each tuple must include\n        a matched-dataset name and condition (ct or pt).'''\n        path_cvapipe = Path(config[\"project\"][\"local_staging\"]).parent\n        self.datasets = {\n            \"M1M2\": {\n                \"ct\": f\"{path_cvapipe}/local_staging_variance_m1m2\",\n                \"pt\": f\"{path_cvapipe}/local_staging_m1m2\"\n            },\n            \"M3\": {\n                \"ct\": f\"{path_cvapipe}/local_staging_variance_m3\",\n                \"pt\": f\"{path_cvapipe}/local_staging_m3\"\n            }}\n\n        self.comparisons = {\n            \"Control vs. M1M2\": [(\"M1M2\", \"ct\"), (\"M1M2\", \"pt\")],\n            \"M1M2 vs. M3\": [(\"M1M2\", \"pt\"), (\"M3\", \"pt\")],\n            \"Control vs. M3\": [(\"M3\", \"ct\"), (\"M3\", \"pt\")],\n            \"ControlM1M2 vs. ControlM3\": [(\"M1M2\", \"ct\"), (\"M3\", \"ct\")]\n        }\n\n    def get_unique_combinations_of_comparisons(self):\n        df = pd.DataFrame([])\n        for _, ((a1, p1), (a2, p2)) in self.comparisons.items():\n            for a, p in zip([a1, a2], [p1, p2]):\n                df = df.append({\"alias\": a, \"phenotype\": p}, ignore_index=True)\n        return df.drop_duplicates().reset_index(drop=True)\n    \n    def load_agg_correlation_data(self):\n        '''Loads the correlation matrix for each pair (alias, condition)\n        as well as the number of cells used to calculate the correlations.'''\n        data = []\n        for _, comb in self.get_unique_combinations_of_comparisons().iterrows():\n            path = Path(self.datasets[comb.alias][comb.phenotype]) / \"concordance\"\n            control, dev = get_managers_from_step_path(path)\n            variables = control.get_variables_values_for_aggregation()\n            df_agg = shapespace.ShapeSpaceBasic.get_aggregated_df(variables)\n            df_agg = df_agg.drop(columns=[\"structure\"]).drop_duplicates().reset_index(drop=True)\n            for _, row in df_agg.iterrows():\n                df_corr, prefix, df_size = dev.get_mean_correlation_matrix_of_reps(row, return_ncells=True)\n                dfs = {\"corr\": df_corr, \"size\": df_size}\n                data.append((comb.alias, comb.phenotype, prefix, dfs))\n        self.data = dict()\n        for k1, k2, k3, value in data:\n            self.data.setdefault(k1, {}).setdefault(k2, {}).update({k3: value})\n\n    def set_df_of_error_curves(self, df):\n        self.df_error = df.copy()        \n\n    def calculate_swaps(self, a1, p1, a2, p2):\n        '''By defining the prefix as below we are explicitly using the fact\n        that matched-datasets have been processed using a single shape mode\n        binned in a single bin.'''\n        np.random.seed(42)\n        prefix = [k for k in self.data[a1][p1].keys()][0]\n        genes = self.data[a1][p1][prefix][\"corr\"].index\n        df_swap = pd.DataFrame(0, index=genes, columns=genes)\n        for gid1, gene1 in tqdm(enumerate(genes), total=len(genes), leave=False):\n            for gid2, gene2 in enumerate(genes):\n                if gid2 >= gid1:\n                    n11 = self.data[a1][p1][prefix][\"size\"].at[gene1, \"ncells\"]\n                    n12 = self.data[a1][p1][prefix][\"size\"].at[gene2, \"ncells\"]\n                    n21 = self.data[a2][p2][prefix][\"size\"].at[gene1, \"ncells\"]\n                    n22 = self.data[a2][p2][prefix][\"size\"].at[gene2, \"ncells\"]\n                    n1 = n11\n                    n2 = n22\n                    corr1 = self.data[a1][p1][prefix][\"corr\"].at[gene1, gene2]\n                    corr2 = self.data[a2][p2][prefix][\"corr\"].at[gene1, gene2]\n                    std1 = self.get_scale(gene1, gene2, n1)\n                    std2 = self.get_scale(gene1, gene2, n2)\n                    swap = self.bootstrap(corr1, std1, corr2, std2)\n                    df_swap.loc[gene1, gene2] = df_swap.loc[gene2, gene1] = swap\n        return df_swap\n\n    def get_scale(self, gene1, gene2, n):\n        '''Remove 1 from the ratio to get a proxy for the variation\n        around the true value. Limiting scale to 0 in case it goes\n        negative due to stochastic fluctuations.'''\n        n = 400 if n > 400 else n\n        index = (gene1, gene2, n)\n        if index in self.df_error.index:\n            return self.df_error.at[index, \"std\"]\n        return self.df_error.at[(gene2, gene1, n), \"std\"]\n\n    @staticmethod\n    def bootstrap(x1, scale1, x2, scale2):\n        count = 0\n        NRUNS = 100\n        for r in range(NRUNS):\n            x1_new = np.random.normal(loc=x1, scale=abs(x1)*scale1)\n            x2_new = np.random.normal(loc=x2, scale=abs(x2)*scale2)\n            count += int(~np.logical_xor(x1>=x2, x1_new>=x2_new))\n        return 1. - count/NRUNS\n    \n    def execute(self):\n        dfs = {}\n        for _, ((a1, p1), (a2, p2)) in self.comparisons.items():\n            df_swap = self.calculate_swaps(a1, p1, a2, p2)\n            dfs[f\"{a1}_{p1}_{a2}_{p2}\"] = df_swap\n        return dfs\n",
        "MakeContrastTable.ipynb": "{\n \"cells\": [\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 10,\n   \"id\": \"b402ed37\",\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"# Single cell instances for contact sheet\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 11,\n   \"id\": \"12ffd6df\",\n   \"metadata\": {},\n   \"outputs\": [\n    {\n     \"name\": \"stdout\",\n     \"output_type\": \"stream\",\n     \"text\": [\n      \"/allen/aics/assay-dev/MicroscopyOtherData/Viana/projects/cvapipe_analysis/local_staging_notebooks/MovieEdges\\n\",\n      \"Sun Jun 26 01:17:45 PDT 2022\\n\"\n     ]\n    }\n   ],\n   \"source\": [\n    \"!pwd\\n\",\n    \"!date\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 19,\n   \"id\": \"19e31877\",\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"import os\\n\",\n    \"import sys\\n\",\n    \"import json\\n\",\n    \"import importlib\\n\",\n    \"import concurrent\\n\",\n    \"import numpy as np\\n\",\n    \"import pandas as pd\\n\",\n    \"from pathlib import Path\\n\",\n    \"from tqdm.notebook import tqdm\\n\",\n    \"from skimage import io as skio\\n\",\n    \"import matplotlib.pyplot as plt\\n\",\n    \"from aicscytoparam import cytoparam\\n\",\n    \"from aicsshparam import shtools, shparam\\n\",\n    \"from aicsimageio import AICSImage\\n\",\n    \"from aicsimageio.writers import OmeTiffWriter\\n\",\n    \"from cvapipe_analysis.tools import io, viz, general, controller, shapespace, plotting\\n\",\n    \"\\n\",\n    \"sys.path.insert(1, '../tools')\\n\",\n    \"import common\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 13,\n   \"id\": \"ee4e913a\",\n   \"metadata\": {},\n   \"outputs\": [\n    {\n     \"name\": \"stdout\",\n     \"output_type\": \"stream\",\n     \"text\": [\n      \"/allen/aics/assay-dev/MicroscopyOtherData/Viana/projects/cvapipe_analysis/local_staging_variance\\n\"\n     ]\n    }\n   ],\n   \"source\": [\n    \"path_config = Path(\\\"/allen/aics/assay-dev/MicroscopyOtherData/Viana/projects/cvapipe_analysis/\\\")\\n\",\n    \"control_main = controller.Controller(general.load_config_file(path_config))\\n\",\n    \"device_main = io.LocalStagingIO(control_main)\\n\",\n    \"print(control_main.get_staging())\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 14,\n   \"id\": \"ea558e9f\",\n   \"metadata\": {},\n   \"outputs\": [\n    {\n     \"name\": \"stdout\",\n     \"output_type\": \"stream\",\n     \"text\": [\n      \"(216062, 46)\\n\"\n     ]\n    }\n   ],\n   \"source\": [\n    \"df = device_main.load_step_manifest(\\\"loaddata\\\")\\n\",\n    \"print(df.shape)\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 15,\n   \"id\": \"f28d8461\",\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"genes = control_main.get_gene_names()\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 16,\n   \"id\": \"7da8ee27\",\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"morphs = dict([(gene, []) for gene in genes])\\n\",\n    \"\\n\",\n    \"inner_alias = control_main.get_inner_most_alias_to_parameterize()\\n\",\n    \"outer_alias = control_main.get_outer_most_alias_to_parameterize()\\n\",\n    \"inner_mesh = device_main.read_vtk_polydata(f\\\"avgshape/edges_{inner_alias}_matched.vtk\\\")\\n\",\n    \"outer_mesh = device_main.read_vtk_polydata(f\\\"avgshape/edges_{outer_alias}_matched.vtk\\\")\\n\",\n    \"\\n\",\n    \"path_step = Path(\\\"/allen/aics/assay-dev/MicroscopyOtherData/Viana/projects/cvapipe_analysis/local_staging_variance_edges/shapemode\\\")\\n\",\n    \"control, device = common.get_managers_from_step_path(path_step)\\n\",\n    \"\\n\",\n    \"row = pd.Series({\\\"shape_mode\\\": \\\"NUC_MEM_PC1\\\", \\\"mpId\\\": 1, \\\"aggtype\\\": \\\"avg\\\", \\\"alias\\\": \\\"STR\\\"})\\n\",\n    \"domain, domain_nuc, domain_mem, coords_param = common.get_map_point_shape(control, device, row, inner_mesh=inner_mesh, outer_mesh=outer_mesh)\\n\",\n    \"\\n\",\n    \"for gene in genes:\\n\",\n    \"    row[\\\"structure\\\"] = gene\\n\",\n    \"    rep = device.read_agg_parameterized_intensity(row)\\n\",\n    \"    morphed = cytoparam.morph_representation_on_shape(\\n\",\n    \"        img=domain,\\n\",\n    \"        param_img_coords=coords_param,\\n\",\n    \"        representation=rep\\n\",\n    \"    )\\n\",\n    \"    morphed = np.stack([domain_nuc, domain_mem, morphed], axis=0)\\n\",\n    \"    morphs[gene].append(morphed)\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 22,\n   \"id\": \"6dc07c93\",\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"contrast = {}\\n\",\n    \"for gene in genes:\\n\",\n    \"    mode = {\\\"nuc\\\":\\\"center_nuc\\\",\\\"mem\\\":\\\"center_nuc\\\",\\\"gfp\\\":\\\"center_nuc\\\"}\\n\",\n    \"    contrast[gene] = common.Projector.get_shared_morphed_max_based_on_pct_for_zy_views(\\n\",\n    \"        instances = morphs[gene],\\n\",\n    \"        pct = 95,\\n\",\n    \"        mode = mode,\\n\",\n    \"        func = np.mean\\n\",\n    \"    )\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 23,\n   \"id\": \"fdb7ddad\",\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"log = {\\\"contrast\\\": contrast, \\\"version\\\": {}}\\n\",\n    \"for fname in [\\\"../tools/common.py\\\", \\\"MakeContrastTable.ipynb\\\"]:\\n\",\n    \"    with open(fname, \\\"r\\\") as ftxt:\\n\",\n    \"        log[\\\"version\\\"][fname] = ftxt.read()\\n\",\n    \"with open(\\\"contrast_V2_95OnValids.json\\\", \\\"w\\\") as fj:\\n\",\n    \"    json.dump(log, fj, indent=4)\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 24,\n   \"id\": \"43317dbd\",\n   \"metadata\": {},\n   \"outputs\": [\n    {\n     \"name\": \"stdout\",\n     \"output_type\": \"stream\",\n     \"text\": [\n      \"complete. 2022-06-26 02:56:39\\n\"\n     ]\n    }\n   ],\n   \"source\": [\n    \"common.now(\\\"complete.\\\")\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"id\": \"483bce70\",\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": []\n  }\n ],\n \"metadata\": {\n  \"kernelspec\": {\n   \"display_name\": \"Python 3 (ipykernel)\",\n   \"language\": \"python\",\n   \"name\": \"python3\"\n  },\n  \"language_info\": {\n   \"codemirror_mode\": {\n    \"name\": \"ipython\",\n    \"version\": 3\n   },\n   \"file_extension\": \".py\",\n   \"mimetype\": \"text/x-python\",\n   \"name\": \"python\",\n   \"nbconvert_exporter\": \"python\",\n   \"pygments_lexer\": \"ipython3\",\n   \"version\": \"3.8.12\"\n  }\n },\n \"nbformat\": 4,\n \"nbformat_minor\": 5\n}\n"
    }
}